# CausalFlow: Ki·∫øn tr√∫c M·∫°ng N∆°-ron S√¢u H·ª£p nh·∫•t trong Kh√°m ph√° C·∫•u tr√∫c Nh√¢n qu·∫£

[![Architecture](https://img.shields.io/badge/Architecture-Detailed_Diagrams-blueviolet?style=flat-square)](ARCH.md)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg?style=flat-square)](LICENSE)

---

## üìù T·ªïng quan (Abstract)

D·ª± √°n **CausalFlow** ƒë·ªÅ xu·∫•t m·ªôt gi·∫£i ph√°p h·ªçc s√¢u (Deep Learning) ti√™n ti·∫øn nh·∫±m gi·∫£i quy·∫øt b√†i to√°n kh√°m ph√° c·∫•u tr√∫c nh√¢n qu·∫£ (Causal Discovery) t·ª´ d·ªØ li·ªáu quan s√°t phi tuy·∫øn. H·ªá th·ªëng ƒë∆∞·ª£c thi·∫øt k·∫ø d·ª±a tr√™n tri·∫øt l√Ω "M√¥ h√¨nh h·ª£p nh·∫•t" (Unified Model), t√≠ch h·ª£p ƒë·ªìng th·ªùi vi·ªác h·ªçc ƒë·∫∑c tr∆∞ng th√¥ng qua c√°c m·∫°ng n∆°-ron s√¢u v√† t·ªëi ∆∞u h√≥a ƒë·ªì th·ªã c√≥ h∆∞·ªõng kh√¥ng v√≤ng (DAG) d·ª±a tr√™n c√°c r√†ng bu·ªôc to√°n h·ªçc li√™n t·ª•c. K·∫øt qu·∫£ th·ª±c nghi·ªám tr√™n b·ªô d·ªØ li·ªáu protein th·ª±c t·∫ø cho th·∫•y m√¥ h√¨nh ƒë·∫°t ƒë·ªô ch√≠nh x√°c cao trong vi·ªác x√°c ƒë·ªãnh h∆∞·ªõng nh√¢n qu·∫£, ƒë·ªìng th·ªùi cung c·∫•p kh·∫£ nƒÉng ph√¢n t√≠ch gi·∫£ t∆∞·ªüng m·∫°nh m·∫Ω cho c√°c b√†i to√°n can thi·ªáp d·ªØ li·ªáu.

## 1. Gi·ªõi thi·ªáu (Introduction)

Trong b·ªëi c·∫£nh khoa h·ªçc d·ªØ li·ªáu hi·ªán ƒë·∫°i, vi·ªác x√°c ƒë·ªãnh m·ªëi quan h·ªá nh√¢n qu·∫£ (Causality) thay v√¨ ch·ªâ d·ª´ng l·∫°i ·ªü m·ªëi li√™n quan (Correlation) ƒë√≥ng vai tr√≤ s·ªëng c√≤n trong c√°c lƒ©nh v·ª±c nh∆∞ y sinh, kinh t·∫ø v√† tr√≠ tu·ªá nh√¢n t·∫°o gi·∫£i th√≠ch ƒë∆∞·ª£c. C√°c ph∆∞∆°ng ph√°p truy·ªÅn th·ªëng th∆∞·ªùng g·∫∑p kh√≥ khƒÉn khi ƒë·ªëi m·∫∑t v·ªõi d·ªØ li·ªáu c√≥ t√≠nh ch·∫•t phi tuy·∫øn b·∫≠c cao v√† ph√¢n ph·ªëi nhi·ªÖu ph·ª©c t·∫°p.

**CausalFlow** ra ƒë·ªùi v·ªõi m·ª•c ti√™u chuy·ªÉn ƒë·ªïi c√°c ph∆∞∆°ng ph√°p nghi√™n c·ª©u r·ªùi r·∫°c (t√¨nh tr·∫°ng chung c·ªßa c√°c thu·∫≠t to√°n ti·ªÅn nhi·ªám nh∆∞ GPPOM-HSIC) th√†nh m·ªôt **Engine nh√¢n qu·∫£** ho√†n ch·ªânh. B·∫±ng c√°ch k·∫øt h·ª£p gi·ªØa m·∫°ng n∆°-ron Spline Flow v√† t·ªëi ∆∞u h√≥a NOTEARS, CausalFlow kh√¥ng ch·ªâ t√¨m th·∫•y c·∫•u tr√∫c ƒë·ªì th·ªã m√† c√≤n h·ªçc ƒë∆∞·ª£c c∆° ch·∫ø sinh d·ªØ li·ªáu (Data Generating Process), cho ph√©p th·ª±c hi·ªán c√°c ph√©p th·ª≠ "What-if" ƒë·∫ßy ti·ªÅm nƒÉng.

---

## 2. ƒê·∫∑c t·∫£ K·ªπ thu·∫≠t v√† C√¥ng ngh·ªá SOTA

Ki·∫øn tr√∫c CausalFlow ƒë∆∞·ª£c x√¢y d·ª±ng t·ª´ c√°c th√†nh ph·∫ßn c√¥ng ngh·ªá hi·ªán ƒë·∫°i nh·∫•t (State-of-the-art):

*   **Deep Neural Backbone (ResNet + GRN + Attention):** H·ªá th·ªëng tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng s·ª≠ d·ª•ng c√°c kh·ªëi ResNet k·∫øt h·ª£p v·ªõi Gated Residual Networks (GRN) cho ph√©p m√¥ h√¨nh t·ª± ƒë·ªông ch·ªçn l·ªçc c√°c bi·∫øn ƒë·∫ßu v√†o c√≥ ·∫£nh h∆∞·ªüng nh√¢n qu·∫£, ƒë·ªìng th·ªùi b·ªè qua c√°c bi·∫øn g√¢y nhi·ªÖu.
*   **Neural Spline Flows (NSF):** Kh√°c v·ªõi c√°c gi·∫£ ƒë·ªãnh nhi·ªÖu ƒë∆°n gi·∫£n, CausalFlow s·ª≠ d·ª•ng c√°c h√†m Spline ƒë∆°n ƒëi·ªáu ƒë·ªÉ m√¥ h√¨nh h√≥a h√†m m·∫≠t ƒë·ªô x√°c su·∫•t c·ªßa nhi·ªÖu. ƒêi·ªÅu n√†y gi√∫p m√¥ h√¨nh "l√†m s·∫°ch" d·ªØ li·ªáu v√† t√°ch bi·ªát nguy√™n nh√¢n - k·∫øt qu·∫£ m·ªôt c√°ch ch√≠nh x√°c h∆°n trong m√¥i tr∆∞·ªùng phi tuy·∫øn.
*   **Differentiable DAG Discovery (NOTEARS):** Chuy·ªÉn ƒë·ªïi b√†i to√°n t√¨m ki·∫øm ƒë·ªì th·ªã r·ªùi r·∫°c th√†nh b√†i to√°n t·ªëi ∆∞u h√≥a li√™n t·ª•c. R√†ng bu·ªôc to√°n h·ªçc ƒë·∫£m b·∫£o ƒë·ªì th·ªã ƒë·∫ßu ra lu√¥n ƒë·∫°t t√≠nh kh√¥ng v√≤ng (Acyclicity).
*   **Hilbert-Schmidt Independence Criterion (HSIC):** ƒê∆∞·ª£c s·ª≠ d·ª•ng nh∆∞ m·ªôt h√†m ph·∫°t (Penalty function) trong qu√° tr√¨nh hu·∫•n luy·ªán ƒë·ªÉ c∆∞·ª°ng b·ª©c t√≠nh ƒë·ªôc l·∫≠p th·ªëng k√™ gi·ªØa ph·∫ßn d∆∞ (residuals) v√† bi·∫øn nguy√™n nh√¢n, ƒë√¢y l√† ƒëi·ªÅu ki·ªán ti√™n quy·∫øt trong l√Ω thuy·∫øt nh√¢n qu·∫£ ANM.

---

## 3. S·ª± ti·∫øn h√≥a v√† C·∫£i ti·∫øn H·ªá th·ªëng

B·∫£ng d∆∞·ªõi ƒë√¢y t√≥m t·∫Øt s·ª± l·ªôt x√°c c·ªßa d·ª± √°n t·ª´ phi√™n b·∫£n nghi√™n c·ª©u ban ƒë·∫ßu (`amber0309`) sang Framework `CausalFlow`:

| Kh√≠a c·∫°nh | D·ª± √°n Base (amber0309) | **CausalFlow (Ours)** | Gi√° tr·ªã khoa h·ªçc |
| :--- | :--- | :--- | :--- |
| **Ki·∫øn tr√∫c m√£** | Script r·ªùi r·∫°c, c·∫•u tr√∫c ph·∫≥ng | **C·∫•u tr√∫c ph√¢n l·ªõp (Modularized)** | TƒÉng t√≠nh t√°i s·ª≠ d·ª•ng v√† kh·∫£ nƒÉng b·∫£o tr√¨. |
| **M√¥ h√¨nh h√≥a** | MLP ƒë∆°n gi·∫£n, nhi·ªÖu Gauss | **Deep ResNet & Spline Flows** | Kh·∫£ nƒÉng bi·ªÉu di·ªÖn c√°c c∆° ch·∫ø phi tuy·∫øn c·ª±c k·ª≥ ph·ª©c t·∫°p. |
| **T√¨m ki·∫øm ƒë·ªì th·ªã** | Greedy Search / Bivariate | **Multivariate Optimization** | T√¨m ki·∫øm c·∫•u tr√∫c c·ªßa to√†n b·ªô h·ªá th·ªëng bi·∫øn ƒë·ªìng th·ªùi. |
| **API Giao ti·∫øp** | G·ªçi h√†m th·ªß c√¥ng | **Unified Model Class API** | ƒê·ªìng nh·∫•t h√≥a lu·ªìng hu·∫•n luy·ªán v√† suy di·ªÖn (Inference). |
| **·ª®ng d·ª•ng** | Ch·ªâ t√¨m h∆∞·ªõng | **Counterfactual & Stability** | Kh·∫£ nƒÉng th·∫©m ƒë·ªãnh ƒë·ªô b·ªÅn v·ªØng v√† m√¥ ph·ªèng can thi·ªáp. |
| **Ti·ªÅn x·ª≠ l√Ω** | C∆° b·∫£n | **Hybrid Preprocessing Pipeline** | (IsoForest + Quantile) T·ªëi ∆∞u h√≥a d·ªØ li·ªáu ƒë·∫ßu v√†o. |

---

## 4. H∆∞·ªõng d·∫´n C√†i ƒë·∫∑t v√† S·ª≠ d·ª•ng

### C√†i ƒë·∫∑t
```bash
pip install git+https://github.com/manhthai1706/CausalFlow.git
```

### S·ª≠ d·ª•ng API H·ª£p nh·∫•t
D·ª± √°n ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ s·ª≠ d·ª•ng ƒë∆°n gi·∫£n nh∆∞ c√°c th∆∞ vi·ªán ML hi·ªán ƒë·∫°i:

**1. X√°c ƒë·ªãnh h∆∞·ªõng nh√¢n qu·∫£ cho c·∫∑p bi·∫øn:**
```python
from causalflow import CausalFlow
model = CausalFlow(lda=12.0)
direction = model.predict_direction(data) # Tr·∫£ v·ªÅ h∆∞·ªõng t·ªëi ∆∞u
```

**2. Hu·∫•n luy·ªán ƒëa bi·∫øn v√† l·∫•y ma tr·∫≠n DAG:**
```python
model = CausalFlow(data=X_matrix) # T·ª± ƒë·ªông nh·∫≠n di·ªán v√† hu·∫•n luy·ªán
W_raw, W_binary = model.get_dag_matrix()
```

---

## 5. K·∫øt qu·∫£ Th·ª±c nghi·ªám v√† Th·∫£o lu·∫≠n (Results)

Hi·ªáu su·∫•t c·ªßa CausalFlow ƒë∆∞·ª£c ki·ªÉm ch·ª©ng kh·∫Øt khe tr√™n b·ªô d·ªØ li·ªáu th·ª±c t·∫ø **Sachs (Protein Signaling Network)**:

*   **ƒê·ªô ch√≠nh x√°c x√°c ƒë·ªãnh h∆∞·ªõng (Accuracy): 70.6%** (X√°c ƒë·ªãnh ƒë√∫ng 12/17 c·∫°nh nh√¢n qu·∫£ th·ª±c t·∫ø).
*   **SHD (Structural Hamming Distance): 5** (M·ª©c sai s·ªë c·∫•u tr√∫c r·∫•t th·∫•p so v·ªõi c√°c ph∆∞∆°ng ph√°p c√πng lo·∫°i).
*   **ƒê·ªô ·ªïn ƒë·ªãnh:** M√¥ h√¨nh duy tr√¨ hi·ªáu nƒÉng cao nh·ªù kh·∫£ nƒÉng l·ªçc nhi·ªÖu sinh h·ªçc b·∫±ng Isolation Forest.

### B·∫£ng so s√°nh hi·ªáu nƒÉng

| Thu·∫≠t to√°n | C∆° ch·∫ø Phi tuy·∫øn | ƒê·ªô ch√≠nh x√°c (Sachs) | SHD | T√≠nh ·ªïn ƒë·ªãnh |
| :--- | :--- | :--- | :--- | :--- |
| **PC Algorithm** | Y·∫øu | ~50-55% | Cao | Th·∫•p |
| **NOTEARS (Original)** | Trung b√¨nh | ~60% | > 8 | Trung b√¨nh |
| **CausalFlow (Ours)** | **R·∫•t t·ªët (NSF)** | **70.6%** | **5** | **Cao** |

---

## 6. Tham kh·∫£o (References)

1.  **ANM-MM (amber0309).** [GitHub Repository](https://github.com/amber0309/ANM-MM). (C∆° s·ªü thu·∫≠t to√°n ban ƒë·∫ßu).
2.  **Zheng, X., et al. (2018).** "DAGs with NO TEARS: Continuous Optimization for Structure Learning." *NeurIPS*.
3.  **Durkan, C., et al. (2019).** "Neural Spline Flows." *NeurIPS*.
4.  **Zhang, K., & Hyvarinen, A. (2009).** "On the Identifiability of the Post-Nonlinear Causal Model." *UAI*.
5.  **Rahimi, A., & Recht, B. (2007).** "Random Features for Large-Scale Kernel Machines." *NeurIPS*.
6.  **Gretton, A., et al. (2007).** "A Kernel Statistical Test of Independence." *NeurIPS*.
7.  **Vaswani, A., et al. (2017).** "Attention Is All You Need." *NeurIPS*.
8.  **Jang, E., et al. (2016).** "Categorical Reparameterization with Gumbel-Softmax." *ICLR*.
9.  **Kingma, D. P., & Welling, M. (2013).** "Auto-Encoding Variational Bayes." *ICLR*.
10. **He, K., et al. (2016).** "Deep Residual Learning for Image Recognition." *CVPR*.
11. **Ba, J. L., et al. (2016).** "Layer Normalization." *arXiv*.
12. **Hendrycks, D., & Gimpel, K. (2016).** "Gaussian Error Linear Units (GELUs)." *arXiv*.
13. **Lim, B., et al. (2021).** "Temporal Fusion Transformers (GRN)." *IJF*.
14. **Loshchilov, I., & Hutter, F. (2017).** "Decoupled Weight Decay Regularization." *ICLR*.
15. **Liu, F. T., et al. (2008).** "Isolation Forest." *ICDM*.
16. **Pedregosa, F., et al. (2011).** "Scikit-learn: Machine Learning in Python." *JMLR*.
17. **Paszke, A., et al. (2019).** "PyTorch: An Imperative Style, High-Performance Deep Learning Library." *NeurIPS*.

## Gi·∫•y ph√©p (License)
D·ª± √°n ƒë∆∞·ª£c ph√°t h√†nh d∆∞·ªõi gi·∫•y ph√©p MIT License.
